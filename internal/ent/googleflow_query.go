/*
	Copyright 2023 Loophole Labs

	Licensed under the Apache License, Version 2.0 (the "License");
	you may not use this file except in compliance with the License.
	You may obtain a copy of the License at

		   http://www.apache.org/licenses/LICENSE-2.0

	Unless required by applicable law or agreed to in writing, software
	distributed under the License is distributed on an "AS IS" BASIS,
	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	See the License for the specific language governing permissions and
	limitations under the License.
*/

// Code generated by ent, DO NOT EDIT.

package ent

import (
	"context"
	"fmt"
	"math"

	"entgo.io/ent/dialect/sql"
	"entgo.io/ent/dialect/sql/sqlgraph"
	"entgo.io/ent/schema/field"
	"github.com/loopholelabs/auth/internal/ent/googleflow"
	"github.com/loopholelabs/auth/internal/ent/predicate"
)

// GoogleFlowQuery is the builder for querying GoogleFlow entities.
type GoogleFlowQuery struct {
	config
	ctx        *QueryContext
	order      []OrderFunc
	inters     []Interceptor
	predicates []predicate.GoogleFlow
	// intermediate query (i.e. traversal path).
	sql  *sql.Selector
	path func(context.Context) (*sql.Selector, error)
}

// Where adds a new predicate for the GoogleFlowQuery builder.
func (gfq *GoogleFlowQuery) Where(ps ...predicate.GoogleFlow) *GoogleFlowQuery {
	gfq.predicates = append(gfq.predicates, ps...)
	return gfq
}

// Limit the number of records to be returned by this query.
func (gfq *GoogleFlowQuery) Limit(limit int) *GoogleFlowQuery {
	gfq.ctx.Limit = &limit
	return gfq
}

// Offset to start from.
func (gfq *GoogleFlowQuery) Offset(offset int) *GoogleFlowQuery {
	gfq.ctx.Offset = &offset
	return gfq
}

// Unique configures the query builder to filter duplicate records on query.
// By default, unique is set to true, and can be disabled using this method.
func (gfq *GoogleFlowQuery) Unique(unique bool) *GoogleFlowQuery {
	gfq.ctx.Unique = &unique
	return gfq
}

// Order specifies how the records should be ordered.
func (gfq *GoogleFlowQuery) Order(o ...OrderFunc) *GoogleFlowQuery {
	gfq.order = append(gfq.order, o...)
	return gfq
}

// First returns the first GoogleFlow entity from the query.
// Returns a *NotFoundError when no GoogleFlow was found.
func (gfq *GoogleFlowQuery) First(ctx context.Context) (*GoogleFlow, error) {
	nodes, err := gfq.Limit(1).All(setContextOp(ctx, gfq.ctx, "First"))
	if err != nil {
		return nil, err
	}
	if len(nodes) == 0 {
		return nil, &NotFoundError{googleflow.Label}
	}
	return nodes[0], nil
}

// FirstX is like First, but panics if an error occurs.
func (gfq *GoogleFlowQuery) FirstX(ctx context.Context) *GoogleFlow {
	node, err := gfq.First(ctx)
	if err != nil && !IsNotFound(err) {
		panic(err)
	}
	return node
}

// FirstID returns the first GoogleFlow ID from the query.
// Returns a *NotFoundError when no GoogleFlow ID was found.
func (gfq *GoogleFlowQuery) FirstID(ctx context.Context) (id int, err error) {
	var ids []int
	if ids, err = gfq.Limit(1).IDs(setContextOp(ctx, gfq.ctx, "FirstID")); err != nil {
		return
	}
	if len(ids) == 0 {
		err = &NotFoundError{googleflow.Label}
		return
	}
	return ids[0], nil
}

// FirstIDX is like FirstID, but panics if an error occurs.
func (gfq *GoogleFlowQuery) FirstIDX(ctx context.Context) int {
	id, err := gfq.FirstID(ctx)
	if err != nil && !IsNotFound(err) {
		panic(err)
	}
	return id
}

// Only returns a single GoogleFlow entity found by the query, ensuring it only returns one.
// Returns a *NotSingularError when more than one GoogleFlow entity is found.
// Returns a *NotFoundError when no GoogleFlow entities are found.
func (gfq *GoogleFlowQuery) Only(ctx context.Context) (*GoogleFlow, error) {
	nodes, err := gfq.Limit(2).All(setContextOp(ctx, gfq.ctx, "Only"))
	if err != nil {
		return nil, err
	}
	switch len(nodes) {
	case 1:
		return nodes[0], nil
	case 0:
		return nil, &NotFoundError{googleflow.Label}
	default:
		return nil, &NotSingularError{googleflow.Label}
	}
}

// OnlyX is like Only, but panics if an error occurs.
func (gfq *GoogleFlowQuery) OnlyX(ctx context.Context) *GoogleFlow {
	node, err := gfq.Only(ctx)
	if err != nil {
		panic(err)
	}
	return node
}

// OnlyID is like Only, but returns the only GoogleFlow ID in the query.
// Returns a *NotSingularError when more than one GoogleFlow ID is found.
// Returns a *NotFoundError when no entities are found.
func (gfq *GoogleFlowQuery) OnlyID(ctx context.Context) (id int, err error) {
	var ids []int
	if ids, err = gfq.Limit(2).IDs(setContextOp(ctx, gfq.ctx, "OnlyID")); err != nil {
		return
	}
	switch len(ids) {
	case 1:
		id = ids[0]
	case 0:
		err = &NotFoundError{googleflow.Label}
	default:
		err = &NotSingularError{googleflow.Label}
	}
	return
}

// OnlyIDX is like OnlyID, but panics if an error occurs.
func (gfq *GoogleFlowQuery) OnlyIDX(ctx context.Context) int {
	id, err := gfq.OnlyID(ctx)
	if err != nil {
		panic(err)
	}
	return id
}

// All executes the query and returns a list of GoogleFlows.
func (gfq *GoogleFlowQuery) All(ctx context.Context) ([]*GoogleFlow, error) {
	ctx = setContextOp(ctx, gfq.ctx, "All")
	if err := gfq.prepareQuery(ctx); err != nil {
		return nil, err
	}
	qr := querierAll[[]*GoogleFlow, *GoogleFlowQuery]()
	return withInterceptors[[]*GoogleFlow](ctx, gfq, qr, gfq.inters)
}

// AllX is like All, but panics if an error occurs.
func (gfq *GoogleFlowQuery) AllX(ctx context.Context) []*GoogleFlow {
	nodes, err := gfq.All(ctx)
	if err != nil {
		panic(err)
	}
	return nodes
}

// IDs executes the query and returns a list of GoogleFlow IDs.
func (gfq *GoogleFlowQuery) IDs(ctx context.Context) ([]int, error) {
	var ids []int
	ctx = setContextOp(ctx, gfq.ctx, "IDs")
	if err := gfq.Select(googleflow.FieldID).Scan(ctx, &ids); err != nil {
		return nil, err
	}
	return ids, nil
}

// IDsX is like IDs, but panics if an error occurs.
func (gfq *GoogleFlowQuery) IDsX(ctx context.Context) []int {
	ids, err := gfq.IDs(ctx)
	if err != nil {
		panic(err)
	}
	return ids
}

// Count returns the count of the given query.
func (gfq *GoogleFlowQuery) Count(ctx context.Context) (int, error) {
	ctx = setContextOp(ctx, gfq.ctx, "Count")
	if err := gfq.prepareQuery(ctx); err != nil {
		return 0, err
	}
	return withInterceptors[int](ctx, gfq, querierCount[*GoogleFlowQuery](), gfq.inters)
}

// CountX is like Count, but panics if an error occurs.
func (gfq *GoogleFlowQuery) CountX(ctx context.Context) int {
	count, err := gfq.Count(ctx)
	if err != nil {
		panic(err)
	}
	return count
}

// Exist returns true if the query has elements in the graph.
func (gfq *GoogleFlowQuery) Exist(ctx context.Context) (bool, error) {
	ctx = setContextOp(ctx, gfq.ctx, "Exist")
	switch _, err := gfq.FirstID(ctx); {
	case IsNotFound(err):
		return false, nil
	case err != nil:
		return false, fmt.Errorf("ent: check existence: %w", err)
	default:
		return true, nil
	}
}

// ExistX is like Exist, but panics if an error occurs.
func (gfq *GoogleFlowQuery) ExistX(ctx context.Context) bool {
	exist, err := gfq.Exist(ctx)
	if err != nil {
		panic(err)
	}
	return exist
}

// Clone returns a duplicate of the GoogleFlowQuery builder, including all associated steps. It can be
// used to prepare common query builders and use them differently after the clone is made.
func (gfq *GoogleFlowQuery) Clone() *GoogleFlowQuery {
	if gfq == nil {
		return nil
	}
	return &GoogleFlowQuery{
		config:     gfq.config,
		ctx:        gfq.ctx.Clone(),
		order:      append([]OrderFunc{}, gfq.order...),
		inters:     append([]Interceptor{}, gfq.inters...),
		predicates: append([]predicate.GoogleFlow{}, gfq.predicates...),
		// clone intermediate query.
		sql:  gfq.sql.Clone(),
		path: gfq.path,
	}
}

// GroupBy is used to group vertices by one or more fields/columns.
// It is often used with aggregate functions, like: count, max, mean, min, sum.
//
// Example:
//
//	var v []struct {
//		CreatedAt time.Time `json:"created_at,omitempty"`
//		Count int `json:"count,omitempty"`
//	}
//
//	client.GoogleFlow.Query().
//		GroupBy(googleflow.FieldCreatedAt).
//		Aggregate(ent.Count()).
//		Scan(ctx, &v)
func (gfq *GoogleFlowQuery) GroupBy(field string, fields ...string) *GoogleFlowGroupBy {
	gfq.ctx.Fields = append([]string{field}, fields...)
	grbuild := &GoogleFlowGroupBy{build: gfq}
	grbuild.flds = &gfq.ctx.Fields
	grbuild.label = googleflow.Label
	grbuild.scan = grbuild.Scan
	return grbuild
}

// Select allows the selection one or more fields/columns for the given query,
// instead of selecting all fields in the entity.
//
// Example:
//
//	var v []struct {
//		CreatedAt time.Time `json:"created_at,omitempty"`
//	}
//
//	client.GoogleFlow.Query().
//		Select(googleflow.FieldCreatedAt).
//		Scan(ctx, &v)
func (gfq *GoogleFlowQuery) Select(fields ...string) *GoogleFlowSelect {
	gfq.ctx.Fields = append(gfq.ctx.Fields, fields...)
	sbuild := &GoogleFlowSelect{GoogleFlowQuery: gfq}
	sbuild.label = googleflow.Label
	sbuild.flds, sbuild.scan = &gfq.ctx.Fields, sbuild.Scan
	return sbuild
}

// Aggregate returns a GoogleFlowSelect configured with the given aggregations.
func (gfq *GoogleFlowQuery) Aggregate(fns ...AggregateFunc) *GoogleFlowSelect {
	return gfq.Select().Aggregate(fns...)
}

func (gfq *GoogleFlowQuery) prepareQuery(ctx context.Context) error {
	for _, inter := range gfq.inters {
		if inter == nil {
			return fmt.Errorf("ent: uninitialized interceptor (forgotten import ent/runtime?)")
		}
		if trv, ok := inter.(Traverser); ok {
			if err := trv.Traverse(ctx, gfq); err != nil {
				return err
			}
		}
	}
	for _, f := range gfq.ctx.Fields {
		if !googleflow.ValidColumn(f) {
			return &ValidationError{Name: f, err: fmt.Errorf("ent: invalid field %q for query", f)}
		}
	}
	if gfq.path != nil {
		prev, err := gfq.path(ctx)
		if err != nil {
			return err
		}
		gfq.sql = prev
	}
	return nil
}

func (gfq *GoogleFlowQuery) sqlAll(ctx context.Context, hooks ...queryHook) ([]*GoogleFlow, error) {
	var (
		nodes = []*GoogleFlow{}
		_spec = gfq.querySpec()
	)
	_spec.ScanValues = func(columns []string) ([]any, error) {
		return (*GoogleFlow).scanValues(nil, columns)
	}
	_spec.Assign = func(columns []string, values []any) error {
		node := &GoogleFlow{config: gfq.config}
		nodes = append(nodes, node)
		return node.assignValues(columns, values)
	}
	for i := range hooks {
		hooks[i](ctx, _spec)
	}
	if err := sqlgraph.QueryNodes(ctx, gfq.driver, _spec); err != nil {
		return nil, err
	}
	if len(nodes) == 0 {
		return nodes, nil
	}
	return nodes, nil
}

func (gfq *GoogleFlowQuery) sqlCount(ctx context.Context) (int, error) {
	_spec := gfq.querySpec()
	_spec.Node.Columns = gfq.ctx.Fields
	if len(gfq.ctx.Fields) > 0 {
		_spec.Unique = gfq.ctx.Unique != nil && *gfq.ctx.Unique
	}
	return sqlgraph.CountNodes(ctx, gfq.driver, _spec)
}

func (gfq *GoogleFlowQuery) querySpec() *sqlgraph.QuerySpec {
	_spec := &sqlgraph.QuerySpec{
		Node: &sqlgraph.NodeSpec{
			Table:   googleflow.Table,
			Columns: googleflow.Columns,
			ID: &sqlgraph.FieldSpec{
				Type:   field.TypeInt,
				Column: googleflow.FieldID,
			},
		},
		From:   gfq.sql,
		Unique: true,
	}
	if unique := gfq.ctx.Unique; unique != nil {
		_spec.Unique = *unique
	}
	if fields := gfq.ctx.Fields; len(fields) > 0 {
		_spec.Node.Columns = make([]string, 0, len(fields))
		_spec.Node.Columns = append(_spec.Node.Columns, googleflow.FieldID)
		for i := range fields {
			if fields[i] != googleflow.FieldID {
				_spec.Node.Columns = append(_spec.Node.Columns, fields[i])
			}
		}
	}
	if ps := gfq.predicates; len(ps) > 0 {
		_spec.Predicate = func(selector *sql.Selector) {
			for i := range ps {
				ps[i](selector)
			}
		}
	}
	if limit := gfq.ctx.Limit; limit != nil {
		_spec.Limit = *limit
	}
	if offset := gfq.ctx.Offset; offset != nil {
		_spec.Offset = *offset
	}
	if ps := gfq.order; len(ps) > 0 {
		_spec.Order = func(selector *sql.Selector) {
			for i := range ps {
				ps[i](selector)
			}
		}
	}
	return _spec
}

func (gfq *GoogleFlowQuery) sqlQuery(ctx context.Context) *sql.Selector {
	builder := sql.Dialect(gfq.driver.Dialect())
	t1 := builder.Table(googleflow.Table)
	columns := gfq.ctx.Fields
	if len(columns) == 0 {
		columns = googleflow.Columns
	}
	selector := builder.Select(t1.Columns(columns...)...).From(t1)
	if gfq.sql != nil {
		selector = gfq.sql
		selector.Select(selector.Columns(columns...)...)
	}
	if gfq.ctx.Unique != nil && *gfq.ctx.Unique {
		selector.Distinct()
	}
	for _, p := range gfq.predicates {
		p(selector)
	}
	for _, p := range gfq.order {
		p(selector)
	}
	if offset := gfq.ctx.Offset; offset != nil {
		// limit is mandatory for offset clause. We start
		// with default value, and override it below if needed.
		selector.Offset(*offset).Limit(math.MaxInt32)
	}
	if limit := gfq.ctx.Limit; limit != nil {
		selector.Limit(*limit)
	}
	return selector
}

// GoogleFlowGroupBy is the group-by builder for GoogleFlow entities.
type GoogleFlowGroupBy struct {
	selector
	build *GoogleFlowQuery
}

// Aggregate adds the given aggregation functions to the group-by query.
func (gfgb *GoogleFlowGroupBy) Aggregate(fns ...AggregateFunc) *GoogleFlowGroupBy {
	gfgb.fns = append(gfgb.fns, fns...)
	return gfgb
}

// Scan applies the selector query and scans the result into the given value.
func (gfgb *GoogleFlowGroupBy) Scan(ctx context.Context, v any) error {
	ctx = setContextOp(ctx, gfgb.build.ctx, "GroupBy")
	if err := gfgb.build.prepareQuery(ctx); err != nil {
		return err
	}
	return scanWithInterceptors[*GoogleFlowQuery, *GoogleFlowGroupBy](ctx, gfgb.build, gfgb, gfgb.build.inters, v)
}

func (gfgb *GoogleFlowGroupBy) sqlScan(ctx context.Context, root *GoogleFlowQuery, v any) error {
	selector := root.sqlQuery(ctx).Select()
	aggregation := make([]string, 0, len(gfgb.fns))
	for _, fn := range gfgb.fns {
		aggregation = append(aggregation, fn(selector))
	}
	if len(selector.SelectedColumns()) == 0 {
		columns := make([]string, 0, len(*gfgb.flds)+len(gfgb.fns))
		for _, f := range *gfgb.flds {
			columns = append(columns, selector.C(f))
		}
		columns = append(columns, aggregation...)
		selector.Select(columns...)
	}
	selector.GroupBy(selector.Columns(*gfgb.flds...)...)
	if err := selector.Err(); err != nil {
		return err
	}
	rows := &sql.Rows{}
	query, args := selector.Query()
	if err := gfgb.build.driver.Query(ctx, query, args, rows); err != nil {
		return err
	}
	defer rows.Close()
	return sql.ScanSlice(rows, v)
}

// GoogleFlowSelect is the builder for selecting fields of GoogleFlow entities.
type GoogleFlowSelect struct {
	*GoogleFlowQuery
	selector
}

// Aggregate adds the given aggregation functions to the selector query.
func (gfs *GoogleFlowSelect) Aggregate(fns ...AggregateFunc) *GoogleFlowSelect {
	gfs.fns = append(gfs.fns, fns...)
	return gfs
}

// Scan applies the selector query and scans the result into the given value.
func (gfs *GoogleFlowSelect) Scan(ctx context.Context, v any) error {
	ctx = setContextOp(ctx, gfs.ctx, "Select")
	if err := gfs.prepareQuery(ctx); err != nil {
		return err
	}
	return scanWithInterceptors[*GoogleFlowQuery, *GoogleFlowSelect](ctx, gfs.GoogleFlowQuery, gfs, gfs.inters, v)
}

func (gfs *GoogleFlowSelect) sqlScan(ctx context.Context, root *GoogleFlowQuery, v any) error {
	selector := root.sqlQuery(ctx)
	aggregation := make([]string, 0, len(gfs.fns))
	for _, fn := range gfs.fns {
		aggregation = append(aggregation, fn(selector))
	}
	switch n := len(*gfs.selector.flds); {
	case n == 0 && len(aggregation) > 0:
		selector.Select(aggregation...)
	case n != 0 && len(aggregation) > 0:
		selector.AppendSelect(aggregation...)
	}
	rows := &sql.Rows{}
	query, args := selector.Query()
	if err := gfs.driver.Query(ctx, query, args, rows); err != nil {
		return err
	}
	defer rows.Close()
	return sql.ScanSlice(rows, v)
}
